{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore the dataset\n",
    "There are 10 variables:\n",
    "\n",
    "* sbp: Systolic blood pressure\n",
    "* tobacco: Cumulative tobacco consumption, in kg\n",
    "* ldl: Low-density lipoprotein cholesterol\n",
    "* adiposity: Adipose tissue concentration\n",
    "* famhist: Family history of heart disease (1=Present, 0=Absent)\n",
    "* typea: Score on test designed to measure type-A behavior\n",
    "* obesity: Obesity\n",
    "* alcohol: Current consumption of alcohol\n",
    "* age: Age of subject\n",
    "* chd: Coronary heart disease at baseline; 1=Yes 0=No\n",
    "    \n",
    "Each following row contains the information of one patient. There are 462 samples in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>Present</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>Absent</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>Present</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>Present</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>Present</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  age  chd\n",
       "0  160    12.00  5.73      23.11  Present     49    25.30    97.20   52    1\n",
       "1  144     0.01  4.41      28.61   Absent     55    28.87     2.06   63    1\n",
       "2  118     0.08  3.48      32.28  Present     52    29.14     3.81   46    0\n",
       "3  170     7.50  6.41      38.03  Present     51    31.99    24.26   58    1\n",
       "4  134    13.60  3.50      27.78  Present     60    25.99    57.34   49    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "* Use pd.get_dummies to specify which columns you want encoded and get a dataframe with original columns replaced with one-hot encodings.\n",
    "* add the encoded dataframe to the dataset and drop the duplicate\n",
    "* Split the data into fetures and albels and drop the labels column from the features\n",
    "* perform min-max scaling, a normalization strategy which linearly transforms x to y= (x-min)/(max-min). when x=min, then y=0, and when x=max, then y=1.\n",
    "* Split the data into train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(data['famhist'],prefix='famhist', drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data,dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "      <th>famhist_Absent</th>\n",
       "      <th>famhist_Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>Present</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>Absent</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>Present</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>Present</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>Present</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  age  chd  \\\n",
       "0  160    12.00  5.73      23.11  Present     49    25.30    97.20   52    1   \n",
       "1  144     0.01  4.41      28.61   Absent     55    28.87     2.06   63    1   \n",
       "2  118     0.08  3.48      32.28  Present     52    29.14     3.81   46    0   \n",
       "3  170     7.50  6.41      38.03  Present     51    31.99    24.26   58    1   \n",
       "4  134    13.60  3.50      27.78  Present     60    25.99    57.34   49    1   \n",
       "\n",
       "   famhist_Absent  famhist_Present  \n",
       "0               0                1  \n",
       "1               1                0  \n",
       "2               0                1  \n",
       "3               0                1  \n",
       "4               0                1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['famhist'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "      <th>famhist_Absent</th>\n",
       "      <th>famhist_Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  typea  obesity  alcohol  age  chd  \\\n",
       "0  160    12.00  5.73      23.11     49    25.30    97.20   52    1   \n",
       "1  144     0.01  4.41      28.61     55    28.87     2.06   63    1   \n",
       "2  118     0.08  3.48      32.28     52    29.14     3.81   46    0   \n",
       "3  170     7.50  6.41      38.03     51    31.99    24.26   58    1   \n",
       "4  134    13.60  3.50      27.78     60    25.99    57.34   49    1   \n",
       "\n",
       "   famhist_Absent  famhist_Present  \n",
       "0               0                1  \n",
       "1               1                0  \n",
       "2               0                1  \n",
       "3               0                1  \n",
       "4               0                1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=['sbp','tobacco','ldl','adiposity','typea','obesity','alcohol','age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['chd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in inputs:\n",
    "    data[each] = ( data[each] - data[each].min() ) / data[each].max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sbp   tobacco       ldl  adiposity     typea   obesity   alcohol  \\\n",
      "0  0.283654  0.384615  0.309850   0.323370  0.461538  0.162087  0.660371   \n",
      "1  0.206731  0.000321  0.223744   0.452812  0.538462  0.238729  0.013996   \n",
      "2  0.081731  0.002564  0.163079   0.539186  0.500000  0.244526  0.025885   \n",
      "3  0.331731  0.240385  0.354207   0.674512  0.487179  0.305711  0.164821   \n",
      "4  0.158654  0.435897  0.164384   0.433278  0.602564  0.176900  0.389565   \n",
      "\n",
      "        age  chd  famhist_Absent  famhist_Present  \n",
      "0  0.578125    1               0                1  \n",
      "1  0.750000    1               1                0  \n",
      "2  0.484375    0               0                1  \n",
      "3  0.671875    1               0                1  \n",
      "4  0.531250    1               0                1  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303,)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(['chd'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>famhist_Absent</th>\n",
       "      <th>famhist_Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283654</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.309850</td>\n",
       "      <td>0.323370</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.162087</td>\n",
       "      <td>0.660371</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.206731</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.223744</td>\n",
       "      <td>0.452812</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.238729</td>\n",
       "      <td>0.013996</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081731</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.163079</td>\n",
       "      <td>0.539186</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.244526</td>\n",
       "      <td>0.025885</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.331731</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.354207</td>\n",
       "      <td>0.674512</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.305711</td>\n",
       "      <td>0.164821</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158654</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.433278</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.389565</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sbp   tobacco       ldl  adiposity     typea   obesity   alcohol  \\\n",
       "0  0.283654  0.384615  0.309850   0.323370  0.461538  0.162087  0.660371   \n",
       "1  0.206731  0.000321  0.223744   0.452812  0.538462  0.238729  0.013996   \n",
       "2  0.081731  0.002564  0.163079   0.539186  0.500000  0.244526  0.025885   \n",
       "3  0.331731  0.240385  0.354207   0.674512  0.487179  0.305711  0.164821   \n",
       "4  0.158654  0.435897  0.164384   0.433278  0.602564  0.176900  0.389565   \n",
       "\n",
       "        age  famhist_Absent  famhist_Present  \n",
       "0  0.578125               0                1  \n",
       "1  0.750000               1                0  \n",
       "2  0.484375               0                1  \n",
       "3  0.671875               0                1  \n",
       "4  0.531250               0                1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 303\n"
     ]
    }
   ],
   "source": [
    "print(len(features), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(features, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 10) (242,)\n"
     ]
    }
   ],
   "source": [
    "print (train_X.shape, train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 10) (61,)\n"
     ]
    }
   ],
   "source": [
    "print (test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters\n",
    "* Number of labels\n",
    "* Number of features\n",
    "* Learning rate\n",
    "* Number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "earning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs= 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden1 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a classifer model\n",
    "* Define placeholders for labels and inputs\n",
    "* Define operations for weights and bias\n",
    "* Define softmax cross entropy as the loss funciton, minimize it for the cost fucntion and set gradient descent as the optimizer.\n",
    "* Define a variable initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32,[None, 10], name ='inputs' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.placeholder(tf.int32, [None,], name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_one_hot = tf.one_hot(labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.truncated_normal([n_features,n_hidden1], stddev=0.1)),\n",
    "    'output':tf.Variable(tf.truncated_normal([n_hidden1, n_labels], stddev=0.1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = {\n",
    "    'hidden_layer':tf.Variable(tf.zeros([n_hidden1])),\n",
    "    'output':tf.Variable(tf.zeros(n_labels))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = tf.nn.bias_add(tf.matmul(inputs,weights['hidden_layer']), bias['hidden_layer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = tf.nn.relu(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.nn.bias_add(tf.matmul(hidden_layer, weights['output']), bias['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the model\n",
    "* Start the session\n",
    "* Initialize the variables\n",
    "* Print the loss after every epoch\n",
    "* Test the model for correct predictions and calculate the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ; training loss: 0.6929178237915039\n",
      "Epoch: 1 ; training loss: 0.6892012357711792\n",
      "Epoch: 2 ; training loss: 0.6858416199684143\n",
      "Epoch: 3 ; training loss: 0.6827988028526306\n",
      "Epoch: 4 ; training loss: 0.680014967918396\n",
      "Epoch: 5 ; training loss: 0.6774773001670837\n",
      "Epoch: 6 ; training loss: 0.6751903891563416\n",
      "Epoch: 7 ; training loss: 0.6731235980987549\n",
      "Epoch: 8 ; training loss: 0.671241819858551\n",
      "Epoch: 9 ; training loss: 0.6695281267166138\n",
      "Epoch: 10 ; training loss: 0.6679601073265076\n",
      "Epoch: 11 ; training loss: 0.6665526628494263\n",
      "Epoch: 12 ; training loss: 0.665275514125824\n",
      "Epoch: 13 ; training loss: 0.6641184091567993\n",
      "Epoch: 14 ; training loss: 0.6630815863609314\n",
      "Epoch: 15 ; training loss: 0.6621429920196533\n",
      "Epoch: 16 ; training loss: 0.6612824201583862\n",
      "Epoch: 17 ; training loss: 0.6604915857315063\n",
      "Epoch: 18 ; training loss: 0.659765362739563\n",
      "Epoch: 19 ; training loss: 0.6590947508811951\n",
      "Epoch: 20 ; training loss: 0.658475399017334\n",
      "Epoch: 21 ; training loss: 0.6578998565673828\n",
      "Epoch: 22 ; training loss: 0.6573635339736938\n",
      "Epoch: 23 ; training loss: 0.6568589210510254\n",
      "Epoch: 24 ; training loss: 0.656385600566864\n",
      "Epoch: 25 ; training loss: 0.6559405326843262\n",
      "Epoch: 26 ; training loss: 0.6555206179618835\n",
      "Epoch: 27 ; training loss: 0.6551228165626526\n",
      "Epoch: 28 ; training loss: 0.6547448635101318\n",
      "Epoch: 29 ; training loss: 0.6543838381767273\n",
      "Epoch: 30 ; training loss: 0.6540375351905823\n",
      "Epoch: 31 ; training loss: 0.6537041068077087\n",
      "Epoch: 32 ; training loss: 0.6533818244934082\n",
      "Epoch: 33 ; training loss: 0.653069257736206\n",
      "Epoch: 34 ; training loss: 0.6527650356292725\n",
      "Epoch: 35 ; training loss: 0.6524692177772522\n",
      "Epoch: 36 ; training loss: 0.652182400226593\n",
      "Epoch: 37 ; training loss: 0.6519004702568054\n",
      "Epoch: 38 ; training loss: 0.6516225934028625\n",
      "Epoch: 39 ; training loss: 0.6513497233390808\n",
      "Epoch: 40 ; training loss: 0.6510797142982483\n",
      "Epoch: 41 ; training loss: 0.6508115530014038\n",
      "Epoch: 42 ; training loss: 0.6505442261695862\n",
      "Epoch: 43 ; training loss: 0.6502775549888611\n",
      "Epoch: 44 ; training loss: 0.6500109434127808\n",
      "Epoch: 45 ; training loss: 0.6497460603713989\n",
      "Epoch: 46 ; training loss: 0.6494829654693604\n",
      "Epoch: 47 ; training loss: 0.649219810962677\n",
      "Epoch: 48 ; training loss: 0.6489549279212952\n",
      "Epoch: 49 ; training loss: 0.6486888527870178\n",
      "Epoch: 50 ; training loss: 0.6484216451644897\n",
      "Epoch: 51 ; training loss: 0.6481518149375916\n",
      "Epoch: 52 ; training loss: 0.6478791236877441\n",
      "Epoch: 53 ; training loss: 0.6476057767868042\n",
      "Epoch: 54 ; training loss: 0.6473309993743896\n",
      "Epoch: 55 ; training loss: 0.647054135799408\n",
      "Epoch: 56 ; training loss: 0.6467753052711487\n",
      "Epoch: 57 ; training loss: 0.6464939713478088\n",
      "Epoch: 58 ; training loss: 0.6462095975875854\n",
      "Epoch: 59 ; training loss: 0.6459218263626099\n",
      "Epoch: 60 ; training loss: 0.6456306576728821\n",
      "Epoch: 61 ; training loss: 0.6453360915184021\n",
      "Epoch: 62 ; training loss: 0.6450385451316833\n",
      "Epoch: 63 ; training loss: 0.6447374224662781\n",
      "Epoch: 64 ; training loss: 0.6444333791732788\n",
      "Epoch: 65 ; training loss: 0.6441258192062378\n",
      "Epoch: 66 ; training loss: 0.6438143253326416\n",
      "Epoch: 67 ; training loss: 0.643498957157135\n",
      "Epoch: 68 ; training loss: 0.6431796550750732\n",
      "Epoch: 69 ; training loss: 0.6428561806678772\n",
      "Epoch: 70 ; training loss: 0.6425285935401917\n",
      "Epoch: 71 ; training loss: 0.6421971321105957\n",
      "Epoch: 72 ; training loss: 0.6418614387512207\n",
      "Epoch: 73 ; training loss: 0.6415219902992249\n",
      "Epoch: 74 ; training loss: 0.6411790251731873\n",
      "Epoch: 75 ; training loss: 0.6408320069313049\n",
      "Epoch: 76 ; training loss: 0.6404806971549988\n",
      "Epoch: 77 ; training loss: 0.6401250958442688\n",
      "Epoch: 78 ; training loss: 0.6397653818130493\n",
      "Epoch: 79 ; training loss: 0.6394014954566956\n",
      "Epoch: 80 ; training loss: 0.6390334963798523\n",
      "Epoch: 81 ; training loss: 0.6386613845825195\n",
      "Epoch: 82 ; training loss: 0.6382849812507629\n",
      "Epoch: 83 ; training loss: 0.6379044651985168\n",
      "Epoch: 84 ; training loss: 0.6375195384025574\n",
      "Epoch: 85 ; training loss: 0.6371306777000427\n",
      "Epoch: 86 ; training loss: 0.6367380023002625\n",
      "Epoch: 87 ; training loss: 0.6363406777381897\n",
      "Epoch: 88 ; training loss: 0.635938286781311\n",
      "Epoch: 89 ; training loss: 0.6355319619178772\n",
      "Epoch: 90 ; training loss: 0.6351229548454285\n",
      "Epoch: 91 ; training loss: 0.6347101330757141\n",
      "Epoch: 92 ; training loss: 0.6342939734458923\n",
      "Epoch: 93 ; training loss: 0.6338747143745422\n",
      "Epoch: 94 ; training loss: 0.6334502100944519\n",
      "Epoch: 95 ; training loss: 0.6330225467681885\n",
      "Epoch: 96 ; training loss: 0.6325915455818176\n",
      "Epoch: 97 ; training loss: 0.6321573853492737\n",
      "Epoch: 98 ; training loss: 0.631720244884491\n",
      "Epoch: 99 ; training loss: 0.6312803030014038\n",
      "Epoch: 100 ; training loss: 0.6308375000953674\n",
      "Epoch: 101 ; training loss: 0.6303920745849609\n",
      "Epoch: 102 ; training loss: 0.6299433708190918\n",
      "Epoch: 103 ; training loss: 0.6294893026351929\n",
      "Epoch: 104 ; training loss: 0.6290305256843567\n",
      "Epoch: 105 ; training loss: 0.6285692453384399\n",
      "Epoch: 106 ; training loss: 0.6281057596206665\n",
      "Epoch: 107 ; training loss: 0.6276400685310364\n",
      "Epoch: 108 ; training loss: 0.6271724104881287\n",
      "Epoch: 109 ; training loss: 0.6267033815383911\n",
      "Epoch: 110 ; training loss: 0.626232385635376\n",
      "Epoch: 111 ; training loss: 0.6257603168487549\n",
      "Epoch: 112 ; training loss: 0.6252872347831726\n",
      "Epoch: 113 ; training loss: 0.624812662601471\n",
      "Epoch: 114 ; training loss: 0.6243374943733215\n",
      "Epoch: 115 ; training loss: 0.6238614916801453\n",
      "Epoch: 116 ; training loss: 0.6233847141265869\n",
      "Epoch: 117 ; training loss: 0.6229074597358704\n",
      "Epoch: 118 ; training loss: 0.6224302053451538\n",
      "Epoch: 119 ; training loss: 0.6219526529312134\n",
      "Epoch: 120 ; training loss: 0.621475100517273\n",
      "Epoch: 121 ; training loss: 0.6209977865219116\n",
      "Epoch: 122 ; training loss: 0.6205209493637085\n",
      "Epoch: 123 ; training loss: 0.6200450658798218\n",
      "Epoch: 124 ; training loss: 0.6195699572563171\n",
      "Epoch: 125 ; training loss: 0.6190956234931946\n",
      "Epoch: 126 ; training loss: 0.6186224222183228\n",
      "Epoch: 127 ; training loss: 0.6181505918502808\n",
      "Epoch: 128 ; training loss: 0.6176799535751343\n",
      "Epoch: 129 ; training loss: 0.6172106862068176\n",
      "Epoch: 130 ; training loss: 0.6167433261871338\n",
      "Epoch: 131 ; training loss: 0.6162776947021484\n",
      "Epoch: 132 ; training loss: 0.6158143877983093\n",
      "Epoch: 133 ; training loss: 0.615352988243103\n",
      "Epoch: 134 ; training loss: 0.6148939728736877\n",
      "Epoch: 135 ; training loss: 0.6144371628761292\n",
      "Epoch: 136 ; training loss: 0.6139830350875854\n",
      "Epoch: 137 ; training loss: 0.6135312914848328\n",
      "Epoch: 138 ; training loss: 0.6130825281143188\n",
      "Epoch: 139 ; training loss: 0.6126364469528198\n",
      "Epoch: 140 ; training loss: 0.6121937036514282\n",
      "Epoch: 141 ; training loss: 0.6117534041404724\n",
      "Epoch: 142 ; training loss: 0.6113156676292419\n",
      "Epoch: 143 ; training loss: 0.6108811497688293\n",
      "Epoch: 144 ; training loss: 0.6104498505592346\n",
      "Epoch: 145 ; training loss: 0.6100218296051025\n",
      "Epoch: 146 ; training loss: 0.6095973253250122\n",
      "Epoch: 147 ; training loss: 0.609176516532898\n",
      "Epoch: 148 ; training loss: 0.6087601780891418\n",
      "Epoch: 149 ; training loss: 0.6083476543426514\n",
      "Epoch: 150 ; training loss: 0.6079391241073608\n",
      "Epoch: 151 ; training loss: 0.6075342893600464\n",
      "Epoch: 152 ; training loss: 0.6071336269378662\n",
      "Epoch: 153 ; training loss: 0.6067365407943726\n",
      "Epoch: 154 ; training loss: 0.6063430309295654\n",
      "Epoch: 155 ; training loss: 0.605951726436615\n",
      "Epoch: 156 ; training loss: 0.6055642366409302\n",
      "Epoch: 157 ; training loss: 0.6051806211471558\n",
      "Epoch: 158 ; training loss: 0.6048017144203186\n",
      "Epoch: 159 ; training loss: 0.6044268608093262\n",
      "Epoch: 160 ; training loss: 0.6040561199188232\n",
      "Epoch: 161 ; training loss: 0.6036893725395203\n",
      "Epoch: 162 ; training loss: 0.6033267378807068\n",
      "Epoch: 163 ; training loss: 0.6029682159423828\n",
      "Epoch: 164 ; training loss: 0.6026136875152588\n",
      "Epoch: 165 ; training loss: 0.6022630333900452\n",
      "Epoch: 166 ; training loss: 0.6019163727760315\n",
      "Epoch: 167 ; training loss: 0.6015734076499939\n",
      "Epoch: 168 ; training loss: 0.6012342572212219\n",
      "Epoch: 169 ; training loss: 0.600898802280426\n",
      "Epoch: 170 ; training loss: 0.600567102432251\n",
      "Epoch: 171 ; training loss: 0.600239098072052\n",
      "Epoch: 172 ; training loss: 0.5999146103858948\n",
      "Epoch: 173 ; training loss: 0.5995936989784241\n",
      "Epoch: 174 ; training loss: 0.5992762446403503\n",
      "Epoch: 175 ; training loss: 0.5989622473716736\n",
      "Epoch: 176 ; training loss: 0.5986515879631042\n",
      "Epoch: 177 ; training loss: 0.5983443260192871\n",
      "Epoch: 178 ; training loss: 0.5980402231216431\n",
      "Epoch: 179 ; training loss: 0.5977391600608826\n",
      "Epoch: 180 ; training loss: 0.5974412560462952\n",
      "Epoch: 181 ; training loss: 0.597146213054657\n",
      "Epoch: 182 ; training loss: 0.5968540906906128\n",
      "Epoch: 183 ; training loss: 0.5965648293495178\n",
      "Epoch: 184 ; training loss: 0.5962781310081482\n",
      "Epoch: 185 ; training loss: 0.5959941744804382\n",
      "Epoch: 186 ; training loss: 0.5957129001617432\n",
      "Epoch: 187 ; training loss: 0.5954340696334839\n",
      "Epoch: 188 ; training loss: 0.5951576828956604\n",
      "Epoch: 189 ; training loss: 0.5948836803436279\n",
      "Epoch: 190 ; training loss: 0.5946120619773865\n",
      "Epoch: 191 ; training loss: 0.5943444967269897\n",
      "Epoch: 192 ; training loss: 0.594079315662384\n",
      "Epoch: 193 ; training loss: 0.593816339969635\n",
      "Epoch: 194 ; training loss: 0.5935547351837158\n",
      "Epoch: 195 ; training loss: 0.5932925343513489\n",
      "Epoch: 196 ; training loss: 0.5930322408676147\n",
      "Epoch: 197 ; training loss: 0.5927721261978149\n",
      "Epoch: 198 ; training loss: 0.5925094485282898\n",
      "Epoch: 199 ; training loss: 0.5922560095787048\n",
      "training finished\n",
      "Accuracy: 0.6393443\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        _, loss = sess.run([optimizer, cost], feed_dict={inputs:train_X, labels:train_Y})\n",
    "\n",
    "        print(\"Epoch: {0} ; training loss: {1}\".format(epoch, loss))\n",
    "\n",
    "    print('training finished')\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_one_hot, 1))\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({inputs: test_X, labels: test_Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
